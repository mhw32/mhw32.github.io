<!DOCTYPE html5>
<html>
  <head>
    <!-- meta tags -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="keywords" content="Mike Wu, Hongfei, Mike, Wu, Yale, Invrea, machine learning, AI">
    <meta name="author" content="Mike Wu">
    <meta name="description" content="I'm Mike Wu, a machine learning enthusiast, researcher, entrepreneur, and artist.">
    <!-- css inclusions. -->
    <link rel='stylesheet' href='css/main.css' />
    <link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Montserrat' type='text/css'>
    <link rel='stylesheet' href='https://fonts.googleapis.com/css?family=PT+Sans' type='text/css'>
    <meta name="google-site-verification" content="bStnDdxWK7iCGz7PNTE8m68lxx54yNvb21GUdr4a2nI" />
    <!-- font link. -->
    <link href='https://fonts.googleapis.com/css?family=Roboto:400,300,100' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Sans' rel='stylesheet' type='text/css'>
    <!-- favicon link. -->
    <link rel='icon' href='img/favicon.png' />
    <!-- client-side javascript. -->
    <script src="js/jquery-1.11.2.min.js"></script>
    <title> Mike Wu | Research</title>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-88659652-1', 'auto');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <header>
      <div class="navwrapper">
        <a href="index.html" class="name">Mike Wu</a>
        <nav role="navigation">
          <ul>
            <li><a href="index.html">About</a></li>
            <li><a href="research.html" class="active">Research</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="jobs.html">Industry</a></li>
            <!-- <li><a href="doodles.html">Doodles</a></li> -->
            <li><a href="WuMike_CV_11_19_17.pdf">CV</a></li>
          </ul>
        </nav>
      </div>
    </header>

    <section class="text">
      <p><img src="img/research_img.png" alt="Portrait of Mike Wu" class="fullimg small-avatar"></p>
      <p>Out of the many different avenues of machine learning research, I'm most excited about deep generative models (VAEs, GANs, autoregressive models, etc.) and model interpretability (understanding why deep nets do what they do). You can find some of my published work and talks below.<p>
    </section>

    <!-- <section class="featured">
      <p class="intro-title">Research in Progress</p>
      <table border="0" cellspacing="4" cellpadding="2" class="preprints">
        <tbody>
        </tbody>
      </table>
    </section> -->

    <section class="featured">
      <p class="intro-title">Research Archive</p>
      <table border="0" cellspacing="4" cellpadding="2" class="preprints">
        <tbody>
          <tr>
            <td valign="top">
              <img src="img/interpret.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Beyond Sparsity: Tree Regularization of Deep Models for Interpretability</b>
              <p>
                The lack of interpretability remains a key barrier to the adop- tion of deep models in many applications. In this work, we explicitly regularize deep models so human users might step through the process behind their predictions in little time. Specifically, we train deep timeseries models so their class- probability predictions have high accuracy while being closely modeled by decision trees with few nodes. On several real and synthetic examples, we demonstrate that this new tree- based regularization is distinct from simpler L2 or L1 penal- ties, resulting in more human-interpretable models without sacrificing predictive power.
              </p>
                <a href="#">Mike Wu</a>,
                <a href="#">Michael C. Hughes</a>,
                <a href="#">Sonali Parbhoo</a>,
                <a href="#">Maurizio Zazzi</a>,
                <a href="#">Volker Roth</a>,
                <a href="http://finale.seas.harvard.edu/">Finale Doshi-Velez</a>
              <br>
              <em>AAAI 2018</em><br />
              <em>NIPS 2017 TIML Workshop (Oral Presentation)</em><br />
              <a href="interpretablepaper.pdf">preprint</a>
              | <a href="img/nips17_wumike_poster.pdf">poster</a>
              | <a href="img/wumike-nips17-talk.pdf">
              talk</a>
              | <a href="https://github.com/dtak/tree-regularization-public">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/mimic3.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Predicting intervention onset in the ICU with switching statespace models</b>
              <p>
              The impact of many common intensive care unit interventions have not fully quantified, especially in heteroge- nous patient populations. We train unsupervised switching state autoregressive models on vital signs from the public MIMIC-III database to capture patient movement between physiological states. We compare our learnt belief states to static demographics and raw vital signs in the prediction of five ICU treatments: ventilation, vasopressor adminis- tration, and three transfusions. While custom classifiers can only target one specific clinical event, our model learns physiological states which can help with many interventions. Our learning of robust patient state representations presents an exciting path towards future evidence-driven adminsitration of key clinical interventions.
              </p>
                <a href="http://mghassem.mit.edu/">Maryzeh Ghassemi</a>,
                <a href="#">Mike Wu</a>,
                <a href="#">Michael C. Hughes</a>,
                <a href="http://finale.seas.harvard.edu/">Finale Doshi-Velez</a>
              <br>
              <em>AMIA CRI</em>, 2017<br>
              <b>Nominee for AMIA Clinical Informatics Research Award</b><br />
                <a href="http://mghassem.mit.edu/wp-content/uploads/2017/01/Ghassemi_AMIACRI2017_Predicting_Intervention_Onset.pdf" target="_blank">pdf</a>
                | <a href="https://github.com/dtak/mimic-tools">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/mimic.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Understanding vasopressor intervention and weaning: Risk prediction in a public heterogeneous clinical time series database</b>
              <p>
              The widespread adoption of electronic health records allows us to ask evidence-based questions about the need for and benefits of specific clinical interventions in critical-care settings across large populations. We investigated the prediction of vasopressor administration and weaning in the intensive care unit. Vasopressors are commonly used to control hypotension, and changes in timing and dosage can have a large impact on patient outcomes. We considered a cohort of 15 695 intensive care unit patients without orders for reduced care who were alive 30 days post-discharge. A switching-state autoregressive model (SSAM) was trained to predict the multidimensional physiological time series of patients before, during, and after vasopressor administration. The latent states from the SSAM were used as predictors of vasopressor administration and weaning.
              </p>
                <a href="#">Mike Wu</a>,
                <a href="http://mghassem.mit.edu/">Maryzeh Ghassemi</a>,
                <a href="#">Mengling Feng</a>,
                <a href="#">Leo Anthony Celi</a>,
                <a href="https://www.csail.mit.edu/user/1513">Peter Szolovits</a>,
                <a href="http://finale.seas.harvard.edu/">Finale Doshi-Velez</a>
              <br>
              <em>Journal of the American Medical Informatics Association</em>, 2016<br>
                <a href="http://jamia.oxfordjournals.org/content/early/2016/10/04/jamia.ocw138.abstract" target="_blank">pdf</a>
                | <a href="https://github.com/dtak/mimic-tools">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/spreadsheet.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Spreadsheet Probabilistic Programming</b>
              <p>
              Spreadsheet workbook contents are simple programs. Because of this, probabilistic programming techniques can be used to perform Bayesian inversion of spreadsheet computations. What is more, existing execution engines in spreadsheet applications such as Microsoft Excel can be made to do this using only built-in functionality. We demonstrate this by developing a native Excel implementation of both a particle Markov Chain Monte Carlo variant and black-box variational inference for spreadsheet probabilistic programming. The resulting engine performs probabilistically coherent inference over spreadsheet computations, notably including spreadsheets that include user-defined black-box functions.
              </p>
                <a href="#">Mike Wu</a>,
                <a href="http://yuraperov.com/">Yura Perov</a>,
                <a href="http://www.robots.ox.ac.uk/~fwood/">Frank Wood</a>,
                <a href="http://www.cs.ox.ac.uk/people/hongseok.yang/Public/Home.html">Hongseok Yang</a>
              <br>
              <em>NIPS Salon des Refusés</em>, 2016<br>
                <a href="http://salon-des-refuses.org/nips2016/wu16a.html">pdf</a>
              <br>
            </td>
          </tr>

          <tr>
            <td valign="top">
              <img src="img/astro.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Topological Hypothesis Tests for Large-Scale Structure of the Universe</b>
              <p>
              In order to understand the physics of the Universe, theoretical and computational cosmologists develop large-scale simulations that allow for analyzing the LSS under varying physical assumptions. In particular, different realizations of dark matter, warm and cold, are thought to lead to contrasting velocities of cosmic structure formation. However, rigorous comparisons and inference on such complicated structures can be problematic. We present a framework for hypothesis testing of LSS using persistent homology. The randomness in the data is transferred to randomness in the topological summaries, which provides an infrastructure for inference. We present several test statistics using persistence diagrams, carry-out a simulation study to investigate the suitableness of the proposed test statistics, and finally apply the inference framework to study topological disparities between assumptions of warm and cold dark matter.
              </p>
                <a href="#">Mike Wu</a>,
                <a href="#">Jessica Cisewski</a>,
                <a href="#">Larry Wasserman</a>,
                <a href="#">Brittany Fasy</a>,
                <a href="#">Mark Lovell</a>,
                <a href="#">Wojciech Hellwing</a>
              <br>
              <em>Work in progress</em><br />
              <a href="astropaper.pdf" target="_blank">preprint</a>
              | <a href="https://github.com/mhw32/Persistent-Homology">code</a>
              <br>
            </td>
          </tr>

<!--           <tr>
            <td valign="top">
              <img src="img/socialrob.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Learning to Help: Employing Motion Capture, Computer Vision, and Machine Learning to Enable Human-Robot Interaction</b>
              <p>
              <em>Yale University Computer Science Senior Project</em><br>
              In intelligent and social robotics, one fundamental problem is understanding arbitrarily complex tasks and allowing for the human-assisted completion thereof. In this project, we present the design of a dual-modal system based on infrared and vision inputs to track the spatial coordinates of objects in a scene as they are manipulated to complete some task. The system is used to create a coordinate-based data set from the construction and de-construction of an IKEA chair. Further work is hypothesized in training a reinforcement learning algorithm based on the latent states such that a BAXTER robot can engage properly in the scene.
              </p>
                <a href="#">Mike Wu</a>
                <a href="http://frankjwu.com/">Frank Wu</a>
                <a href="http://scazlab.yale.edu/people/elena-corina-grigore">Corina Grigore</a>
                <a href="http://www.cs.yale.edu/homes/scaz/">Brian Scassellati</a>
              <br>
              <em>None</em>, 2016<br>
                <a href="https://www.youtube.com/watch?v=XAJ15FPc3PY">video</a>
                | <a href="https://github.com/ScazLab/hrteaming-bctask">code</a>
              <br>
            </td>
          </tr> -->
          <tr>
            <td valign="top">
              <img src="img/cusum.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Financial Market Prediction Using Self-Organizing Maps</b>
              <p>
              Given financial data from popular sites like Yahoo and the London Exchange, the presented paper attempts to model and predict stocks that can be considered "good investments". Stocks are characterized by 125 features ranging from gross domestic product to EDIBTA, and are labeled by discrepancies between stock and market price returns. An artificial neural network (Self-Organizing Map) is fitted to train on more than a million data points to predict "good investments" given testing stocks from 2013 and after.
              </p>
              <a href="#">Mike Wu</a>
              <br>
              <em>ArXiv</em>, 2015<br>
                <a href="http://arxiv.org/pdf/1503.02328v1.pdf">pdf</a>
                | <a href="https://github.com/mhw32/Market-Predictor">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/edgedetect.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Edge-based Crowd Detection from Single Image Datasets</b>
              <p>
              This paper describes the design of a crowd-based facial detection and recognition system using only optical features, allowing for robustness in tracking characterizations with applications in security and data extraction. Implementation is divided into three parts: packing information regarding a given image into edge pixels, segmentation into object groups, and circular segmentation. Detection is achieved by filtering the circles and characterizing those with features similar to that of a normal face. Preliminary facial recognition is described by matching feature vectors to each facial region and matching over subsequence image frames. Algorithms were implemented in MATLAB and testing was performed with a low-resolution video camera. Through a number of trials, results show good detection and tracking abilities given small to medium crowd sizes. Several limitations will be addressed.
              </p>
                <a href="#">Mike Wu</a>,
                <a href="#">Madhu Krishnan</a>
              <br>
              <em>International Journal of Computer Science Issues</em>, 2013<br>
                <a href="http://www.ijcsi.org/papers/IJCSI-12-1-1-18-22.pdf">pdf</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/maze.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Autonomous Mapping and Navigation through Utilization of Edge-based Optical Flow and Time-to-Collision</b>
              <p>
              This paper proposes a cost-effective approach to map and navigate an area with only the means of a single, low resolution camera on a "smart robot", avoiding the cost and unreliability of radar/sonar systems. Implementation is divided into three main parts: object detection, autonomous movement, and mapping by spiraling inwards and using the A* Path finding algorithm. Object detection is obtained by editing Horn-Schunck's optical flow algorithm to track pixel brightness factors to subsequent frames, producing outward vectors. These vectors are then focused on the objects using Sobel edge detection. Autonomous movement is achieved by finding the focus of expansion from those vectors and calculating time to collision which are then used to maneuver. Algorithms are programmed in MATLAB and implemented with LEGO Mindstorm NXT 2.0 robot for real-time testing with a low-resolution video camera. Through numerous trials and diversity of the situations, validity of results is ensured to autonomously navigate and map a room using solely optical inputs.
              </p>
                <a href="#">Madhu Krishnan</a>,
                <a href="#">Mike Wu</a>,
                <a href="#">Young Kang</a>,
                <a href="#">Sarah Lee</a>
              <br>
              <em>ARPN Journal of Engineering and Applied Sciences</em>, 2012<br>
                <a href="http://www.arpnjournals.com/jeas/research_papers/rp_2012/jeas_1212_836.pdf">pdf</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/car.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Position and Vector Detection of Blind Spot motion with the Horn-Schunck Optical Flow</b>
              <p>
              The proposed method uses live image footage which, based on calculations of pixel motion, decides whether or not an object is in the blind-spot. If found, the driver is notified by a sensory light or noise built into the vehicle's CPU. The new technology incorporates optical vectors and flow fields rather than expensive radar-waves, creating cheaper detection systems that retain the needed accuracy while adapting to the current processor speeds.
              </p>
                <a href="#">Stephen Yu</a>,
                <a href="#">Mike Wu</a>
              <br>
              <em>ArXiv</em>, 2011 (Printed 2016)<br>
                <a href="http://arxiv.org/pdf/1603.07625v1.pdf">pdf</a>
                | <a href="https://github.com/mhw32/Blind-Spot-Motion-Detection">code</a>
              <br>
            </td>
          </tr>
        </tbody>
      </table>
    </section>

    <section class="featured">
      <p class="intro-title">Talks</p>
      <table border="0" cellspacing="4" cellpadding="2" class="preprints">
        <tbody>
          <tr>
            <td valign="top">
              <img src="img/python.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Python Workshop</b>
              <p>
              Workshop for high schoolers focused on an introduction to computer science principles and the Python programming language. Touched on repetition, recursion, variables, functions, and libraries.
              </p>
              With <a href="http://jchang.me/">Jonathan Chang</a>, <a href="http://www.ktizzel.com/">Kevin Tan</a><br>
              <em><a href="http://codeboola.yhack.org/">Code Boola</a></em>, 2016<br>
              <a href="https://speakerdeck.com/mhw32/python-workshop-1">slides</a>
              | <a href="https://github.com/mhw32/Code-Boola-Python-Workshop">puzzles</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/anglican.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Probabilistic Programming Workshop</b>
              <p>
              Parallel introductions to Anglican and spreadsheet-based probabilistic programming. Sample exercises included seven scientists, simple Gaussian examples, and physics demonstrations. The workshop was open to both academic and industry members.
              </p>
              With <a href="#">Frank Wood</a>, <a href="#">Yura Perov</a><br>
              <em>University of Southampton</em>, 2016<br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/deepdemo.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Deep Learning Workshop</b>
              <p>
              Workshop on the basics of convolutional and recurrent neural networks with applications to real world problems. Presented at the Yale Technology Conference. Material was provided with a tutorial of the Torch programming language detailing MNIST classification.
              </p>
              <em>Yale Technology Conference</em>, 2015<br>
              <a href="https://speakerdeck.com/mhw32/introduction-to-deep-learning">slides</a>
              | <a href="deepdemo.html">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/flaskdemo.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Flask and Angular Workshop</b>
              <p>
              Workshop on building a simple BlackJack application in Flask with Angular.js frontend. Meant for people with experience in Python and little to no experience in web application development.
              </p>
              <em>YHack</em>, 2015<br>
              <a href="https://speakerdeck.com/mhw32/flask-and-angular-yhack-deck">slides</a>
              | <a href="https://github.com/mhw32/yhack-workshop">code</a>
              <br>
            </td>
          </tr>
          <tr>
            <td valign="top">
              <img src="img/mimic2.png" alt="link to pdf" width="130px" border="0px">
            </td>
            <td valign="top">
              <b>Unsupervised Learning in the Medical Domain Talk</b>
              <p>
              Presentation on a switching-state autoregressive model to predict the onset and weaning of interventions in the intensive care unit. Latent features are learned in an unsupervised fashion that aid in successive supervised classification. Presented to the researchers at OpenAI.
              </p>
              <em>Research Talk</em>, 2016<br>
              <a href="https://speakerdeck.com/mhw32/mimic">slides</a>
              <br>
            </td>
          </tr>
        </tbody>
      </table>
    </section>

    <footer>
      <section class="footersection">
        <div class="title">
          <h2>Get in touch.</h2>
          Reach out for anything to everything.
        </div>

        <div class="copyline">
          Copyright &copy; 2016 Mike Wu | <a href="mailto:me@mikehwu.com">me@mikehwu.com</a> | Github (<a href="http://github.com/mhw32">@mhw32</a>) | Medium (<a href="#">@grubiroth</a>) | Profile images filtered with <a href="https://github.com/jcjohnson/neural-style">neural style</a>.
        </div>
      </section>
    </footer>
  </body>
